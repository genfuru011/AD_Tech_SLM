{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genfuru011/AD_Tech_SLM/blob/main/AD_Tech_SLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKdD0fAzU4hX"
      },
      "source": [
        "# AD_Tech_SLM\n",
        "広告特化型 SLM（Small Language Model）開発・運用プロジェクト\n",
        "\n",
        "## プロジェクト概要\n",
        "\n",
        "本プロジェクトは、“広告コピーの品質向上”と“CTR（クリック率）改善”を目指す、広告業界向けの特化型言語モデルを開発・運用するものです。  \n",
        "データ収集からモデル開発・評価・デプロイ・運用まで、一貫したワークフローを設計し、効率的かつ安定的な価値提供を目指します。\n",
        "\n",
        "---\n",
        "\n",
        "## ロードマップ\n",
        "\n",
        "### 短期（2ヶ月）：PoC → 本格トレーニング\n",
        "### 中期（4ヶ月）：デプロイ＋運用パイプライン構築\n",
        "### 長期（6ヶ月以降）：継続的改善・新機能展開\n",
        "\n",
        "---\n",
        "\n",
        "## チューニング手法\n",
        "\n",
        "### 人間のフィードバックを活用（RLHF, DPO手法）\n",
        "- 人間のフィードバックをもとに、より最適なコピーを生成するようモデルを学習させる\n",
        "- 感情制御、要約生成、対話タスクなど、様々なタスクでRLHFと同等かそれ以上の人間選好一致性を示すことが報告されています。特に、トーンやスタイル、特定のコンテンツ指向など、主観的な要素が重要となる場合に効果を発揮します。\n",
        "- 特に、トーンやスタイル、特定のコンテンツ指向など、主観的な要素が重要となる場合に効果を発揮します。\n",
        "- 人間が好む出力と好まない出力のペアデータが不可欠です。このデータの質や量、多様性がモデルの性能に大きく影響します\n",
        "\n",
        "### 必要データアセットJSONL\n",
        "```json\n",
        "{\"prompt\": \"【テーマ】雨の日でもワクワクするニュースアプリを紹介してください\",\n",
        " \"chosen\": \"雨が降っても最新トレンドをスマホでサクッとチェック！天気と話題を同時にキャッチして、移動中も退屈知らず♪\",\n",
        " \"rejected\": \"ニュースが見られるよ！便利！\"}\n",
        "\n",
        "{\"prompt\": \"【テーマ】忙しい会社員が移動中に英語を学べるアプリを紹介してください\",\n",
        " \"chosen\": \"通勤電車で 3 分！AI レッスンがあなたの発音を即フィードバック💡スキマ時間で着実にスキルアップ！\",\n",
        " \"rejected\": \"英語学習ができます。おすすめです。\"}\n",
        "\n",
        "{\"prompt\": \"【テーマ】節電をサポートする家計簿アプリを紹介してください\",\n",
        " \"chosen\": \"家電ごとの電気代を自動計算！グラフでムダを一目で発見して、月末の請求額にもうドキドキしません✨\",\n",
        " \"rejected\": \"節約に役立つアプリです。ぜひ使ってください。\"}\n",
        "```\n",
        "- prompt：コピーを書かせたいお題や前提条件をまとめます。\n",
        "- chosen：CTR が高かった “良い広告テキスト” を入れます。\n",
        "- rejected：CTR が低かった、または不採用になった文を入れます。\n",
        "\n",
        "# settings command\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ライブラリのインストール**"
      ],
      "metadata": {
        "id": "sCmNddrTAtq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =========================================\n",
        "# 1. ライブラリのインストール\n",
        "# -----------------------------------------"
      ],
      "metadata": {
        "id": "qsEFgSW8WFoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform, os, subprocess, textwrap, json, sys\n",
        "print(\"Python   :\", platform.python_version())\n",
        "print(\"CUDA     :\", torch.version.cuda)\n",
        "!nvidia-smi -L    # A100 40GB であることを確認\n"
      ],
      "metadata": {
        "id": "axFT6PancHqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 0. 依存パッケージ（最新版）        ★初回だけ実行で OK\n",
        "# -----------------------------------------------------------\n",
        "!pip install -q --upgrade \\\n",
        "  trl accelerate transformers peft bitsandbytes datasets sentencepiece"
      ],
      "metadata": {
        "id": "oNQhyACScLLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 1. Drive をマウントしてチェックポイント置き場を決定\n",
        "# -----------------------------------------------------------\n",
        "from google.colab import drive, runtime, output\n",
        "drive.mount(\"/content/drive\")\n",
        "CKPT_DIR = \"/content/drive/MyDrive/hf_ckpt/hameln_dpo_lora\""
      ],
      "metadata": {
        "id": "h_pYhduBnxLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 2. Hugging Face 認証   ★Hameln 利用規約に同意済みトークン\n",
        "# -----------------------------------------------------------\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "sjmFco8NcjII",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 3. モデル & トークナイザを 4-bit でロード\n",
        "# -----------------------------------------------------------\n",
        "import torch, os, glob\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "BASE_ID = \"Elizezen/Hameln-japanese-mistral-7B\"\n",
        "\n",
        "bnb_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "tok = AutoTokenizer.from_pretrained(BASE_ID, use_fast=False)\n",
        "tok.pad_token = tok.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_ID,\n",
        "    quantization_config=bnb_cfg,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "-O86CCjcc4li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 4. LoRA 設定\n",
        "# -----------------------------------------------------------\n",
        "from peft import LoraConfig\n",
        "lora_cfg = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "                    \"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "zQQZBoHAeJYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 5. データセット読み込み（HF Hub から直 DL）\n",
        "# -----------------------------------------------------------\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import os, glob\n",
        "\n",
        "# ❶ Drive にキャッシュを作成して再利用\n",
        "DS_CACHE = \"/content/drive/MyDrive/hf_cache/anthropic_jp\"\n",
        "\n",
        "if os.path.exists(DS_CACHE):\n",
        "    print(\"▶ Drive キャッシュから即時ロード …\")\n",
        "    train_ds = load_from_disk(DS_CACHE)\n",
        "else:\n",
        "    print(\"▶ Hugging Face Hub からダウンロード中 …\")\n",
        "    # デフォルト split は train（161k 行）\n",
        "    train_ds = load_dataset(\"shi3z/anthropic_hh_rlhf_japanese\", split=\"train\")\n",
        "    # 選好列はすでに chosen / rejected で揃っているのでリネーム不要 :contentReference[oaicite:0]{index=0}\n",
        "    train_ds.save_to_disk(DS_CACHE)\n",
        "    print(\"✅ Drive に保存しました →\", DS_CACHE)\n",
        "\n",
        "print(\"データ行数:\", len(train_ds), \"/ 列:\", train_ds.column_names)\n"
      ],
      "metadata": {
        "id": "_zKugKlqeyNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 6. DPOConfig ─ こまめ保存 + メモリ削減\n",
        "# -----------------------------------------------------------\n",
        "from trl import DPOConfig\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # 断片化回避\n",
        "\n",
        "dpo_cfg = DPOConfig(\n",
        "    output_dir              = CKPT_DIR,\n",
        "    per_device_train_batch_size = 1,      # メモリ節約\n",
        "    gradient_accumulation_steps = 8,      # 実バッチ 8\n",
        "    gradient_checkpointing      = True,   # 勾配 CP で 30% 節約\n",
        "    num_train_epochs            = 1,\n",
        "    learning_rate               = 2e-4,\n",
        "    beta                        = 0.1,\n",
        "    logging_steps               = 50,\n",
        "    save_steps                  = 200,    # 200 ステップごとに Drive へ保存\n",
        "    eval_steps                  = 200,\n",
        "    bf16                        = True,   # A100 用\n",
        ")"
      ],
      "metadata": {
        "id": "2Q5LOjrqe6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 7. 最新チェックポイントを自動検出\n",
        "# -----------------------------------------------------------\n",
        "ckpts = sorted(glob.glob(f\"{CKPT_DIR}/checkpoint-*\"), key=os.path.getmtime)\n",
        "resume_ckpt = ckpts[-1] if ckpts else None\n",
        "print(\"再開チェックポイント:\", resume_ckpt)\n"
      ],
      "metadata": {
        "id": "R72uyEpPoR5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 8. DPOTrainer 生成 & 学習開始（参照モデルは CPU へ退避）\n",
        "# -----------------------------------------------------------\n",
        "from trl import DPOTrainer\n",
        "trainer = DPOTrainer(\n",
        "    model                 = base_model,\n",
        "    ref_model             = BASE_ID,               # 文字列指定で自動ロード\n",
        "    ref_model_init_kwargs = {\"device_map\":\"cpu\",\n",
        "                             \"load_in_4bit\":True,\n",
        "                             \"low_cpu_mem_usage\":True},\n",
        "    args                  = dpo_cfg,\n",
        "    processing_class      = tok,\n",
        "    train_dataset         = train_ds,\n",
        "    peft_config           = lora_cfg,              # そのまま渡す\n",
        "    resume_from_checkpoint= resume_ckpt,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "uteeM1H3e-1i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 9. 学習完了後の LoRA アダプタ保存\n",
        "# -----------------------------------------------------------\n",
        "trainer.model.save_pretrained(CKPT_DIR + \"/final-lora\")\n",
        "tok.save_pretrained(CKPT_DIR + \"/final-lora\")\n",
        "print(\"✅ すべて完了！（LoRA は Drive に保存済み）\")"
      ],
      "metadata": {
        "id": "n094d8FRoX40"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1jjC9CRpQ51dPcBHFha3fNbVbR3vAQsHD",
      "authorship_tag": "ABX9TyO3F3QBQhEu+x4y5vDxxDHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}