{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, max_length=100):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ\"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ã‚’é™¤å»\n",
    "    if generated_text.startswith(prompt):\n",
    "        generated_text = generated_text[len(prompt):].strip()\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "test_prompts = [\n",
    "    \"æ¬¡ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„: æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®é‡è¦ãªåˆ†é‡ã§ã™\",\n",
    "    \"ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\",\n",
    "    \"æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’èª¬æ˜ã—ã¦ãã ã•ã„: print('Hello World')\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing DPO-trained model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    response = generate_response(model, tokenizer, prompt)\n",
    "    print(f\"\\nTest {i}:\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. çµæœã®å¯è¦–åŒ–ã¨ã¾ã¨ã‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å±¥æ­´ã®å¯è¦–åŒ–\n",
    "if hasattr(dpo_trainer.state, 'log_history'):\n",
    "    log_history = dpo_trainer.state.log_history\n",
    "    \n",
    "    # ãƒ­ã‚¹ã®æ¨ç§»ã‚’æŠ½å‡º\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    steps = []\n",
    "    \n",
    "    for log in log_history:\n",
    "        if 'loss' in log:\n",
    "            train_losses.append(log['loss'])\n",
    "            steps.append(log.get('step', len(train_losses)))\n",
    "        if 'eval_loss' in log:\n",
    "            eval_losses.append(log['eval_loss'])\n",
    "    \n",
    "    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # è¨“ç·´ãƒ­ã‚¹\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(steps, train_losses, 'b-', label='Training Loss')\n",
    "    plt.title('Training Loss Over Time')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # è©•ä¾¡ãƒ­ã‚¹\n",
    "    if eval_losses:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        eval_steps = np.linspace(0, max(steps), len(eval_losses))\n",
    "        plt.plot(eval_steps, eval_losses, 'r-', label='Evaluation Loss')\n",
    "        plt.title('Evaluation Loss Over Time')\n",
    "        plt.xlabel('Steps')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ‰ DPO Training Completed Successfully!\")\n",
    "print(\"\\nğŸ“‹ Summary:\")\n",
    "print(f\"   â€¢ Model: {model_name}\")\n",
    "print(f\"   â€¢ Training samples: {len(train_dataset)}\")\n",
    "print(f\"   â€¢ Evaluation samples: {len(eval_dataset)}\")\n",
    "print(f\"   â€¢ Final training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"   â€¢ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   â€¢ Peak GPU memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’Google Driveã«ä¿å­˜ã—ãŸã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveã«ãƒã‚¦ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Google Driveã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "    import shutil\n",
    "    drive_path = '/content/drive/MyDrive/dpo_model'\n",
    "    \n",
    "    print(f\"ğŸ“ Copying model to Google Drive: {drive_path}\")\n",
    "    shutil.copytree('./final_dpo_model', drive_path, dirs_exist_ok=True)\n",
    "    print(\"âœ… Model saved to Google Drive!\")\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª\n",
    "import os\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    return total_size\n",
    "\n",
    "model_size = get_folder_size('./final_dpo_model')\n",
    "print(f\"\\nğŸ“Š Final model size: {model_size / 1e6:.1f} MB\")\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n",
    "print(\"\\nğŸ“ Model files:\")\n",
    "for root, dirs, files in os.walk('./final_dpo_model'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_size = os.path.getsize(file_path) / 1e6\n",
    "        print(f\"   {file}: {file_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPO Training on Google Colab - ç›´æ¥é¸å¥½æœ€é©åŒ–\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Google Colabã§å®Ÿè¡Œå¯èƒ½ãªDPOï¼ˆDirect Preference Optimizationï¼‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚\n",
    "\n",
    "## ç‰¹å¾´\n",
    "- ğŸš€ Google Colab GPUå¯¾å¿œ\n",
    "- ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’ç›£è¦–\n",
    "- ğŸ’¾ è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜\n",
    "- ğŸ¯ åŠ¹ç‡çš„ãªLoRAå¾®èª¿æ•´\n",
    "\n",
    "## ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶\n",
    "- Google Colab (GPUæ¨å¥¨)\n",
    "- ç´„2-3GB GPU ãƒ¡ãƒ¢ãƒª\n",
    "- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Google Colab ç’°å¢ƒè¨­å®šã¨ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ \n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Google Colabã§ã®å®Ÿè¡Œç¢ºèª\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Colabã‹ã©ã†ã‹ã‚’ç¢ºèª\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ Installing required packages...\")\n",
    "    !pip install transformers[torch] trl peft datasets accelerate bitsandbytes evaluate\n",
    "    !pip install --upgrade torch torchvision torchaudio\n",
    "    print(\"âœ… Package installation completed!\")\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"ğŸ”¥ CUDA is available! Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ CUDA not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"ğŸš€ Using GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ GPU not available, using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU memory usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DPOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆ\n",
    "\n",
    "Colabã§ã¯å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãã®å ´ã§ç”Ÿæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import random\n",
    "\n",
    "def generate_dpo_dataset(num_samples: int = 500) -> List[Dict]:\n",
    "    \"\"\"DPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ\"\"\"\n",
    "    \n",
    "    # æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
    "    tasks = [\n",
    "        {\n",
    "            \"prompt\": \"æ¬¡ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„: {text}\",\n",
    "            \"chosen\": \"ã“ã®æ–‡ç« ã¯{topic}ã«ã¤ã„ã¦è¿°ã¹ã¦ãŠã‚Šã€ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯{point}ã§ã™ã€‚\",\n",
    "            \"rejected\": \"æ–‡ç« ã®å†…å®¹ã¯è¤‡é›‘ã§ã€æ§˜ã€…ãªè¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„: {question}\",\n",
    "            \"chosen\": \"{answer}ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚{detail}\",\n",
    "            \"rejected\": \"ãã®è³ªå•ã¯é›£ã—ã„ã§ã™ã­ã€‚æ§˜ã€…ãªè¦³ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚\",\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’èª¬æ˜ã—ã¦ãã ã•ã„: {code}\",\n",
    "            \"chosen\": \"ã“ã®ã‚³ãƒ¼ãƒ‰ã¯{function}ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚{explanation}\",\n",
    "            \"rejected\": \"ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œã¯è¤‡é›‘ã§ã€è©³ç´°ãªåˆ†æãŒå¿…è¦ã§ã™ã€‚\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    topics = [\"AIæŠ€è¡“\", \"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°\", \"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹\", \"æ©Ÿæ¢°å­¦ç¿’\", \"ã‚¦ã‚§ãƒ–é–‹ç™º\"]\n",
    "    questions = [\"AIã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\", \"æ©Ÿæ¢°å­¦ç¿’ã®ç¨®é¡ã¯ï¼Ÿ\", \"ãƒ‡ãƒ¼ã‚¿åˆ†æã®æ‰‹é †ã¯ï¼Ÿ\"]\n",
    "    codes = [\"def hello(): print('Hello')\", \"x = [1,2,3]; print(sum(x))\", \"import pandas as pd\"]\n",
    "    \n",
    "    dataset = []\n",
    "    for i in range(num_samples):\n",
    "        task = random.choice(tasks)\n",
    "        \n",
    "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ\n",
    "        if \"{text}\" in task[\"prompt\"]:\n",
    "            topic = random.choice(topics)\n",
    "            prompt = task[\"prompt\"].format(text=f\"{topic}ã«é–¢ã™ã‚‹è©³ç´°ãªèª¬æ˜\")\n",
    "            chosen = task[\"chosen\"].format(topic=topic, point=f\"{topic}ã®é‡è¦æ€§\")\n",
    "        elif \"{question}\" in task[\"prompt\"]:\n",
    "            question = random.choice(questions)\n",
    "            prompt = task[\"prompt\"].format(question=question)\n",
    "            chosen = task[\"chosen\"].format(answer=\"AI\", detail=\"äººå·¥çŸ¥èƒ½ã¯è¨ˆç®—æ©Ÿã«ã‚ˆã‚‹çŸ¥çš„ãªå‡¦ç†ã§ã™\")\n",
    "        else:\n",
    "            code = random.choice(codes)\n",
    "            prompt = task[\"prompt\"].format(code=code)\n",
    "            chosen = task[\"chosen\"].format(function=\"é–¢æ•°å®šç¾©\", explanation=\"æŒ‡å®šã•ã‚ŒãŸå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™\")\n",
    "        \n",
    "        dataset.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": chosen,\n",
    "            \"rejected\": task[\"rejected\"]\n",
    "        })\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ\n",
    "print(\"ğŸ”„ Generating DPO dataset...\")\n",
    "dpo_data = generate_dpo_dataset(1000)\n",
    "df = pd.DataFrame(dpo_data)\n",
    "\n",
    "print(f\"âœ… Generated {len(df)} samples\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nğŸ“Š Sample data:\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ\n",
    "print(\"=== Dataset Statistics ===\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Average prompt length: {df['prompt'].str.len().mean():.1f} chars\")\n",
    "print(f\"Average chosen length: {df['chosen'].str.len().mean():.1f} chars\")\n",
    "print(f\"Average rejected length: {df['rejected'].str.len().mean():.1f} chars\")\n",
    "\n",
    "print(\"\\n=== Sample Example ===\")\n",
    "sample = df.iloc[0]\n",
    "print(f\"Prompt: {sample['prompt']}\")\n",
    "print(f\"Chosen: {sample['chosen']}\")\n",
    "print(f\"Rejected: {sample['rejected']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Colab GPUç’°å¢ƒã«é©ã—ãŸè»½é‡ãƒ¢ãƒ‡ãƒ«\n",
    "model_name = \"microsoft/DialoGPT-small\"  # ç´„117M parameters\n",
    "\n",
    "print(f\"ğŸ“¥ Loading model: {model_name}\")\n",
    "\n",
    "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"âœ… Tokenizer loaded successfully\")\n",
    "print(f\"Vocabulary size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆGPUæœ€é©åŒ–ï¼‰\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "print(\"âœ… Base model loaded successfully\")\n",
    "\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç¢ºèª\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 2 / 1e6:.1f} MB (fp16)\")\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory after model loading: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LoRA (Low-Rank Adaptation) è¨­å®š\n",
    "\n",
    "åŠ¹ç‡çš„ãªå¾®èª¿æ•´ã®ãŸã‚ã®LoRAè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAè¨­å®š (Colabç’°å¢ƒæœ€é©åŒ–)\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,  # Low rank for memory efficiency\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],  # DialoGPT specific modules\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# LoRAãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# GPUä½¿ç”¨é‡ã®ç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory after LoRA: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨DPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "# HuggingFace Datasetå½¢å¼ã«å¤‰æ›\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# è¨“ç·´ãƒ»æ¤œè¨¼åˆ†å‰²\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "eval_dataset = dataset_split['test']\n",
    "\n",
    "print(f\"ğŸ“Š Training samples: {len(train_dataset)}\")\n",
    "print(f\"ğŸ“Š Evaluation samples: {len(eval_dataset)}\")\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "print(\"\\nğŸ” Sample training data:\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DPO (Direct Preference Optimization) ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ad_copy(prompt, max_length=150):\n",
    "    \"\"\"åºƒå‘Šã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°\"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.backends.mps.is_available():\n",
    "        inputs = inputs.to(\"mps\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ã‚’é™¤å»\n",
    "    if generated_text.startswith(prompt):\n",
    "        generated_text = generated_text[len(prompt):].strip()\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
    "test_prompt = \"ã€ãƒ†ãƒ¼ãƒã€‘é›¨ã®æ—¥ã§ã‚‚ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\"\n",
    "result = generate_ad_copy(test_prompt)\n",
    "\n",
    "print(f\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {test_prompt}\")\n",
    "print(f\"ç”Ÿæˆçµæœ: {result}\")\n",
    "\n",
    "# DPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\n",
    "training_args = DPOConfig(\n",
    "    output_dir=\"./dpo_results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-6,\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    bf16=False,  # Disable for compatibility\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_checkpointing=True,\n",
    "    max_length=128,\n",
    "    max_prompt_length=64,\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ DPO training configuration created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DPOãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ\n",
    "\n",
    "å®Ÿéš›ã®DPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ `scripts/train_dpo.py` ã‚’ä½¿ç”¨ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "```bash\n",
    "cd /path/to/AD_Tech_SLM\n",
    "python scripts/train_dpo.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³\n",
    "\n",
    "# DPOãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=0.1,  # DPO temperature parameter\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ DPO Trainer initialized\")\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹\n",
    "print(\"\\nğŸ”¥ Starting DPO training...\")\n",
    "print(\"This may take 10-20 minutes depending on your GPU\")\n",
    "\n",
    "train_result = dpo_trainer.train()\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")\n",
    "print(f\"Final train loss: {train_result.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è©•ä¾¡ã™ã‚‹å ´åˆ\n",
    "# ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†å¾Œã«å®Ÿè¡Œ\n",
    "\n",
    "test_prompts = [\n",
    "    \"ã€ãƒ†ãƒ¼ãƒã€‘å¥åº·ç®¡ç†ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
    "    \"ã€ãƒ†ãƒ¼ãƒã€‘æ–™ç†åˆå¿ƒè€…å‘ã‘ã®ãƒ¬ã‚·ãƒ”ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
    "    \"ã€ãƒ†ãƒ¼ãƒã€‘èª­æ›¸å¥½ãã®ãŸã‚ã®é›»å­æ›¸ç±ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
    "]\n",
    "\n",
    "print(\"=== ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===\")\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    result = generate_ad_copy(prompt)\n",
    "    print(f\"\\nãƒ†ã‚¹ãƒˆ {i}:\")\n",
    "    print(f\"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}\")\n",
    "    print(f\"ç”Ÿæˆçµæœ: {result}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®è©•ä¾¡\n",
    "print(\"ğŸ“Š Evaluating trained model...\")\n",
    "eval_results = dpo_trainer.evaluate()\n",
    "\n",
    "print(\"\\nğŸ“ˆ Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
    "print(\"\\nğŸ’¾ Saving trained model...\")\n",
    "dpo_trainer.save_model(\"./final_dpo_model\")\n",
    "tokenizer.save_pretrained(\"./final_dpo_model\")\n",
    "\n",
    "print(\"âœ… Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
