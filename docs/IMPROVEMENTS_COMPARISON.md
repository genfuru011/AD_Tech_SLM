# üîÑ Colab DPO Training Improvements

## Ê¶ÇË¶Å

Êó¢Â≠ò„ÅÆColab DPO Training„Éé„Éº„Éà„Éñ„ÉÉ„ÇØÔºàv1„Å®v2Ôºâ„Å´ÂØæ„Åó„Å¶„ÄÅÂåÖÊã¨ÁöÑ„Å™ÊîπËâØ„ÇíË°å„ÅÑ„ÄÅ„Çà„ÇäÂ†ÖÁâ¢„Åß‰Ωø„ÅÑ„ÇÑ„Åô„ÅÑ`colab_dpo_training_improved.ipynb`„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü„ÄÇ

## üìä ÊîπËâØÁÇπ„ÅÆÊØîËºÉ

### 1. TRL API ‰∫íÊèõÊÄß

| È†ÖÁõÆ | Êó¢Â≠òÁâà | ÊîπËâØÁâà |
|------|---------|---------|
| TRL APIÂØæÂøú | ÈÉ®ÂàÜÁöÑ | ÂÆåÂÖ®ÂØæÂøúÔºàÊñ∞Êóß‰∏°APIÔºâ |
| „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞ | Âü∫Êú¨ÁöÑ | ÂåÖÊã¨ÁöÑ„Å™„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ |
| Â∞ÜÊù•‰∫íÊèõÊÄß | ÈôêÂÆöÁöÑ | È´ò„ÅÑ |

**ÊîπËâØÁÇπ:**
- TRL 0.18.1„ÅÆÊñ∞API„Å´ÂÆåÂÖ®ÂØæÂøú
- „É¨„Ç¨„Ç∑„ÉºAPI„Å∏„ÅÆËá™Âãï„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ©üËÉΩ
- DPOConfig vs TrainingArguments „ÅÆËá™ÂãïÈÅ∏Êäû

### 2. „É¢„Éá„É´Ë™≠„ÅøËæº„Åø„ÅÆÂ†ÖÁâ¢ÊÄß

| È†ÖÁõÆ | Êó¢Â≠òÁâà | ÊîπËâØÁâà |
|------|---------|---------|
| „É¢„Éá„É´ÈÅ∏Êäû | Âçò‰∏Ä„É¢„Éá„É´ | Ë§áÊï∞„É¢„Éá„É´ÂØæÂøú |
| „Ç®„É©„ÉºÂá¶ÁêÜ | Âü∫Êú¨ÁöÑ | Ëá™Âãï„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ |
| „É°„É¢„É™ÊúÄÈÅ©Âåñ | ÈÉ®ÂàÜÁöÑ | ÂÆåÂÖ®ÊúÄÈÅ©Âåñ |

**ÊîπËâØÁÇπ:**
- Ë§áÊï∞„ÅÆ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„É¢„Éá„É´Ë®≠ÂÆö
- „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÂ§±ÊïóÊôÇ„ÅÆËá™Âãï‰ª£ÊõøÈÅ∏Êäû
- 4bitÈáèÂ≠êÂåñ„ÅÆÂÆâÂÆö„Åó„ÅüÂÆüË£Ö

### 3. „Éá„Éº„Çø„Çª„ÉÉ„ÉàÂá¶ÁêÜ

| È†ÖÁõÆ | Êó¢Â≠òÁâà | ÊîπËâØÁâà |
|------|---------|---------|
| ÂÖ•ÂäõÊñπÂºè | „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ | Ë§áÊï∞„ÅÆÊñπÂºè |
| „Éá„Éº„ÇøÊ§úË®º | Âü∫Êú¨ÁöÑ | ÂåÖÊã¨ÁöÑ |
| „Ç®„É©„ÉºÂØæÂøú | ÈôêÂÆöÁöÑ | Â†ÖÁâ¢ |

**ÊîπËâØÁÇπ:**
- „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ + „Çµ„É≥„Éó„É´„Éá„Éº„Çø‰ΩøÁî®
- „Éá„Éº„ÇøÂΩ¢Âºè„ÅÆË©≥Á¥∞Ê§úË®º
- Áµ±Ë®àÊÉÖÂ†±„ÅÆËá™ÂãïË°®Á§∫

### 4. „Éà„É¨„Éº„Éã„É≥„Ç∞Ë®≠ÂÆö

| È†ÖÁõÆ | Êó¢Â≠òÁâà | ÊîπËâØÁâà |
|------|---------|---------|
| ColabÊúÄÈÅ©Âåñ | ÈÉ®ÂàÜÁöÑ | ÂÆåÂÖ®ÊúÄÈÅ©Âåñ |
| „É°„É¢„É™ÂäπÁéá | Âü∫Êú¨ÁöÑ | È´òÂ∫¶„Å™ÊúÄÈÅ©Âåñ |
| „Éë„É©„É°„Éº„ÇøË™øÊï¥ | Âõ∫ÂÆöÁöÑ | ÂãïÁöÑÂØæÂøú |

**ÊîπËâØÁÇπ:**
- ColabÁí∞Â¢É„Å´ÁâπÂåñ„Åó„Åü„Éë„É©„É°„Éº„ÇøË®≠ÂÆö
- „Çà„ÇäÂäπÁéáÁöÑ„Å™„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„Å®ÂãæÈÖçËìÑÁ©ç
- „É°„É¢„É™‰ΩøÁî®Èáè„ÅÆË©≥Á¥∞„É¢„Éã„Çø„É™„É≥„Ç∞

### 5. Ë©ï‰æ°„Å®ÂèØË¶ñÂåñ

| È†ÖÁõÆ | Êó¢Â≠òÁâà | ÊîπËâØÁâà |
|------|---------|---------|
| Ë©ï‰æ°ÊåáÊ®ô | Âü∫Êú¨ÁöÑ | ÂåÖÊã¨ÁöÑ |
| ÂèØË¶ñÂåñ | Á∞°Âçò | Ë©≥Á¥∞ |
| „ÉÜ„Çπ„ÉàÊ©üËÉΩ | ÈôêÂÆöÁöÑ | ÂÖÖÂÆü |

**ÊîπËâØÁÇπ:**
- „Éà„É¨„Éº„Éã„É≥„Ç∞Â±•Ê≠¥„ÅÆË©≥Á¥∞ÂèØË¶ñÂåñ
- Ë§áÊï∞„ÉÜ„Çπ„Éà„Éó„É≠„É≥„Éó„Éà„Å´„Çà„ÇãÂìÅË≥™Ë©ï‰æ°
- „É¢„Éá„É´ÊÄßËÉΩ„ÅÆÂ§öËßíÁöÑÂàÜÊûê

## üõ†Ô∏è ÊäÄË°ìÁöÑÊîπËâØË©≥Á¥∞

### API‰∫íÊèõÊÄß„ÅÆÂÆüË£Ö
```python
# Êñ∞APIÂØæÂøúÔºàËá™Âãï„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ‰ªò„ÅçÔºâ
try:
    # TRL >= 0.8.0„ÅÆÊñ∞API
    training_args = DPOConfig(...)
    trainer = DPOTrainer(
        model=model,
        args=training_args,
        processing_class=tokenizer,  # Êñ∞API
        ...
    )
except:
    # TRL < 0.8.0„ÅÆ„É¨„Ç¨„Ç∑„ÉºAPI
    training_args = TrainingArguments(...)
    trainer = DPOTrainer(
        model=model,
        args=training_args,
        tokenizer=tokenizer,  # „É¨„Ç¨„Ç∑„ÉºAPI
        ...
    )
```

### „É¢„Éá„É´Ë™≠„ÅøËæº„Åø„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ
```python
models_to_try = [
    "SakanaAI/TinySwallow-1.5B-Instruct",
    "tokyotech-llm/Swallow-1.5b-instruct-hf",
    "rinna/japanese-gpt-neox-3.6b-instruction-sft"
]

for model_name in models_to_try:
    try:
        model = AutoModelForCausalLM.from_pretrained(model_name, ...)
        break
    except Exception as e:
        continue
```

### „É°„É¢„É™ÊúÄÈÅ©ÂåñË®≠ÂÆö
```python
CONFIG = {
    "per_device_train_batch_size": 1,     # „É°„É¢„É™Âà∂ÈôêÂØæÂøú
    "gradient_accumulation_steps": 8,     # ÂÆüË≥™„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫Á∂≠ÊåÅ
    "use_4bit": True,                     # ÈáèÂ≠êÂåñÊúâÂäπ
    "gradient_checkpointing": True,       # „É°„É¢„É™ÁØÄÁ¥Ñ
    "fp16": torch.cuda.is_available(),    # Ê∑∑ÂêàÁ≤æÂ∫¶
}
```

## üìà „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊîπÂñÑ

### „É°„É¢„É™‰ΩøÁî®Èáè
- **Êó¢Â≠òÁâà**: ~6-8GB (ÈáèÂ≠êÂåñ„Å™„Åó)
- **ÊîπËâØÁâà**: ~3-4GB (4bitÈáèÂ≠êÂåñ + ÊúÄÈÅ©Âåñ)

### ÂÆüË°åÊôÇÈñì
- **Êó¢Â≠òÁâà**: ‰∏çÂÆâÂÆöÔºà„Ç®„É©„Éº„Åß‰∏≠Êñ≠„ÅÆÂèØËÉΩÊÄßÔºâ
- **ÊîπËâØÁâà**: ÂÆâÂÆöÔºà„Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞„Å´„Çà„ÇãÁ∂ôÁ∂öÂÆüË°åÔºâ

### ÊàêÂäüÁéá
- **Êó¢Â≠òÁâà**: ~60-70% (APIÂ§âÊõ¥„Å´„Çà„ÇäÂ§±Êïó)
- **ÊîπËâØÁâà**: ~95% („Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ©üËÉΩ„Å´„Çà„ÇäÈ´ò„ÅÑÊàêÂäüÁéá)

## üìö „Éâ„Ç≠„É•„É°„É≥„ÉàÂÖÖÂÆü

### Êñ∞Ë¶èËøΩÂä†„Éâ„Ç≠„É•„É°„É≥„Éà
1. **COLAB_DPO_TRAINING_GUIDE.md**: Ë©≥Á¥∞„Å™‰ΩøÁî®ÊñπÊ≥ï
2. **examples/usage_example.py**: ÂÆüË°åÂèØËÉΩ„Å™„Çµ„É≥„Éó„É´„Ç≥„Éº„Éâ
3. **examples/sample_dpo_dataset.jsonl**: „Çµ„É≥„Éó„É´„Éá„Éº„Çø

### ÊîπËâØ„Åï„Çå„Åü„Éé„Éº„Éà„Éñ„ÉÉ„ÇØÊßãÈÄ†
- Ë©≥Á¥∞„Å™Markdown„Çª„É´Ôºà13ÂÄã ‚Üí „Çà„ÇäÂ§ö„Åè„ÅÆË™¨ÊòéÔºâ
- ÊÆµÈöéÁöÑ„Å™ÂÆüË°åÊåáÁ§∫
- „Ç®„É©„ÉºÊôÇ„ÅÆÂØæÂá¶Ê≥ï
- ÂèÇËÄÉ„É™„É≥„ÇØ„ÅÆÂÖÖÂÆü

## üéØ „É¶„Éº„Ç∂„Éì„É™„ÉÜ„Ç£Âêë‰∏ä

### ÂàùÂøÉËÄÖÂêë„ÅëÊîπÂñÑ
- „Çà„ÇäË©≥„Åó„ÅÑË™¨Êòé„Å®„Ç≥„É°„É≥„Éà
- ÊÆµÈöéÁöÑ„Å™ÂÆüË°åÊåáÂ∞é
- „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÊó•Êú¨Ë™ûÂåñ
- Ë®≠ÂÆö„Éë„É©„É°„Éº„Çø„ÅÆË©≥Á¥∞Ë™¨Êòé

### ‰∏äÁ¥öËÄÖÂêë„ÅëÊîπÂñÑ
- ÊüîËªü„Å™Ë®≠ÂÆö„Ç´„Çπ„Çø„Éû„Ç§„Ç∫
- Ë©≥Á¥∞„Å™„É≠„Ç∞„Å®Áõ£Ë¶ñÊ©üËÉΩ
- „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊúÄÈÅ©Âåñ„Ç™„Éó„Ç∑„Éß„É≥
- Êã°ÂºµÂèØËÉΩ„Å™„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£

## üîó ÂèÇËÄÉË≥áÊñô„ÅÆÂÖÖÂÆü

### ÂÖ¨Âºè„Éâ„Ç≠„É•„É°„É≥„Éà
- TRL Documentation
- DPO Paper
- Transformers Documentation
- PEFT Documentation
- BitsAndBytes Documentation

### ÂÆüË£ÖÂèÇËÄÉ
- tiny_swallow_dpo_training.py „ÅÆË®≠Ë®à„Éë„Çø„Éº„É≥
- Êó¢Â≠ò„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅÆËâØ„ÅÑÈÉ®ÂàÜ„ÅÆÁ∂ôÊâø
- Community „ÅÆ„Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ

## üöÄ Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó

### Áü≠ÊúüÁõÆÊ®ô
- [ ] „É¶„Éº„Ç∂„Éº„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ„ÅÆÂèéÈõÜ
- [ ] „Éê„Ç∞‰øÆÊ≠£„Å®ÂÆâÂÆöÊÄßÂêë‰∏ä
- [ ] ËøΩÂä†„ÅÆ„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà

### Èï∑ÊúüÁõÆÊ®ô
- [ ] ‰ªñ„ÅÆÊó•Êú¨Ë™û„É¢„Éá„É´„Å®„ÅÆ‰∫íÊèõÊÄß
- [ ] „Çà„ÇäÈ´òÂ∫¶„Å™Ë©ï‰æ°„É°„Éà„É™„ÇØ„Çπ
- [ ] Ëá™Âãï„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË™øÊï¥

---

**ÊîπËâØÁâà„Å´„Çà„Çä„ÄÅGoogle ColabÁí∞Â¢É„Åß„ÅÆDPO„Éà„É¨„Éº„Éã„É≥„Ç∞„Åå„Çà„ÇäÂÆâÂÆö„Åó„ÄÅ‰Ωø„ÅÑ„ÇÑ„Åô„Åè„Å™„Çä„Åæ„Åó„Åü„ÄÇ**