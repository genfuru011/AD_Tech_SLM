{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genfuru011/AD_Tech_SLM/blob/main/AD_Tech_SLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKdD0fAzU4hX"
      },
      "source": [
        "# AD_Tech_SLM\n",
        "åºƒå‘Šç‰¹åŒ–å‹ SLMï¼ˆSmall Language Modelï¼‰é–‹ç™ºãƒ»é‹ç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ\n",
        "\n",
        "## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦\n",
        "\n",
        "æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€â€œåºƒå‘Šã‚³ãƒ”ãƒ¼ã®å“è³ªå‘ä¸Šâ€ã¨â€œCTRï¼ˆã‚¯ãƒªãƒƒã‚¯ç‡ï¼‰æ”¹å–„â€ã‚’ç›®æŒ‡ã™ã€åºƒå‘Šæ¥­ç•Œå‘ã‘ã®ç‰¹åŒ–å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºãƒ»é‹ç”¨ã™ã‚‹ã‚‚ã®ã§ã™ã€‚  \n",
        "ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«é–‹ç™ºãƒ»è©•ä¾¡ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»é‹ç”¨ã¾ã§ã€ä¸€è²«ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­è¨ˆã—ã€åŠ¹ç‡çš„ã‹ã¤å®‰å®šçš„ãªä¾¡å€¤æä¾›ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n",
        "\n",
        "### çŸ­æœŸï¼ˆ2ãƒ¶æœˆï¼‰ï¼šPoC â†’ æœ¬æ ¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
        "### ä¸­æœŸï¼ˆ4ãƒ¶æœˆï¼‰ï¼šãƒ‡ãƒ—ãƒ­ã‚¤ï¼‹é‹ç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰\n",
        "### é•·æœŸï¼ˆ6ãƒ¶æœˆä»¥é™ï¼‰ï¼šç¶™ç¶šçš„æ”¹å–„ãƒ»æ–°æ©Ÿèƒ½å±•é–‹\n",
        "\n",
        "---\n",
        "\n",
        "## ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•\n",
        "\n",
        "### äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ï¼ˆRLHF, DPOæ‰‹æ³•ï¼‰\n",
        "- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã¨ã«ã€ã‚ˆã‚Šæœ€é©ãªã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹\n",
        "- æ„Ÿæƒ…åˆ¶å¾¡ã€è¦ç´„ç”Ÿæˆã€å¯¾è©±ã‚¿ã‚¹ã‚¯ãªã©ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§RLHFã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®äººé–“é¸å¥½ä¸€è‡´æ€§ã‚’ç¤ºã™ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€ãƒˆãƒ¼ãƒ³ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€ç‰¹å®šã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŒ‡å‘ãªã©ã€ä¸»è¦³çš„ãªè¦ç´ ãŒé‡è¦ã¨ãªã‚‹å ´åˆã«åŠ¹æœã‚’ç™ºæ®ã—ã¾ã™ã€‚\n",
        "- ç‰¹ã«ã€ãƒˆãƒ¼ãƒ³ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€ç‰¹å®šã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŒ‡å‘ãªã©ã€ä¸»è¦³çš„ãªè¦ç´ ãŒé‡è¦ã¨ãªã‚‹å ´åˆã«åŠ¹æœã‚’ç™ºæ®ã—ã¾ã™ã€‚\n",
        "- äººé–“ãŒå¥½ã‚€å‡ºåŠ›ã¨å¥½ã¾ãªã„å‡ºåŠ›ã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ãŒä¸å¯æ¬ ã§ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚„é‡ã€å¤šæ§˜æ€§ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å¤§ããå½±éŸ¿ã—ã¾ã™\n",
        "\n",
        "### å¿…è¦ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚»ãƒƒãƒˆJSONL\n",
        "```json\n",
        "{\"prompt\": \"ã€ãƒ†ãƒ¼ãƒã€‘é›¨ã®æ—¥ã§ã‚‚ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
        " \"chosen\": \"é›¨ãŒé™ã£ã¦ã‚‚æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚¹ãƒãƒ›ã§ã‚µã‚¯ãƒƒã¨ãƒã‚§ãƒƒã‚¯ï¼å¤©æ°—ã¨è©±é¡Œã‚’åŒæ™‚ã«ã‚­ãƒ£ãƒƒãƒã—ã¦ã€ç§»å‹•ä¸­ã‚‚é€€å±ˆçŸ¥ã‚‰ãšâ™ª\",\n",
        " \"rejected\": \"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã‚‰ã‚Œã‚‹ã‚ˆï¼ä¾¿åˆ©ï¼\"}\n",
        "\n",
        "{\"prompt\": \"ã€ãƒ†ãƒ¼ãƒã€‘å¿™ã—ã„ä¼šç¤¾å“¡ãŒç§»å‹•ä¸­ã«è‹±èªã‚’å­¦ã¹ã‚‹ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
        " \"chosen\": \"é€šå‹¤é›»è»Šã§ 3 åˆ†ï¼AI ãƒ¬ãƒƒã‚¹ãƒ³ãŒã‚ãªãŸã®ç™ºéŸ³ã‚’å³ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ğŸ’¡ã‚¹ã‚­ãƒæ™‚é–“ã§ç€å®Ÿã«ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ï¼\",\n",
        " \"rejected\": \"è‹±èªå­¦ç¿’ãŒã§ãã¾ã™ã€‚ãŠã™ã™ã‚ã§ã™ã€‚\"}\n",
        "\n",
        "{\"prompt\": \"ã€ãƒ†ãƒ¼ãƒã€‘ç¯€é›»ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å®¶è¨ˆç°¿ã‚¢ãƒ—ãƒªã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„\",\n",
        " \"chosen\": \"å®¶é›»ã”ã¨ã®é›»æ°—ä»£ã‚’è‡ªå‹•è¨ˆç®—ï¼ã‚°ãƒ©ãƒ•ã§ãƒ ãƒ€ã‚’ä¸€ç›®ã§ç™ºè¦‹ã—ã¦ã€æœˆæœ«ã®è«‹æ±‚é¡ã«ã‚‚ã†ãƒ‰ã‚­ãƒ‰ã‚­ã—ã¾ã›ã‚“âœ¨\",\n",
        " \"rejected\": \"ç¯€ç´„ã«å½¹ç«‹ã¤ã‚¢ãƒ—ãƒªã§ã™ã€‚ãœã²ä½¿ã£ã¦ãã ã•ã„ã€‚\"}\n",
        "```\n",
        "- promptï¼šã‚³ãƒ”ãƒ¼ã‚’æ›¸ã‹ã›ãŸã„ãŠé¡Œã‚„å‰ææ¡ä»¶ã‚’ã¾ã¨ã‚ã¾ã™ã€‚\n",
        "- chosenï¼šCTR ãŒé«˜ã‹ã£ãŸ â€œè‰¯ã„åºƒå‘Šãƒ†ã‚­ã‚¹ãƒˆâ€ ã‚’å…¥ã‚Œã¾ã™ã€‚\n",
        "- rejectedï¼šCTR ãŒä½ã‹ã£ãŸã€ã¾ãŸã¯ä¸æ¡ç”¨ã«ãªã£ãŸæ–‡ã‚’å…¥ã‚Œã¾ã™ã€‚\n",
        "\n",
        "# settings command\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**"
      ],
      "metadata": {
        "id": "sCmNddrTAtq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =========================================\n",
        "# 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# -----------------------------------------"
      ],
      "metadata": {
        "id": "qsEFgSW8WFoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform, os, subprocess, textwrap, json, sys\n",
        "print(\"Python   :\", platform.python_version())\n",
        "print(\"CUDA     :\", torch.version.cuda)\n",
        "!nvidia-smi -L    # A100 40GB ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª\n"
      ],
      "metadata": {
        "id": "axFT6PancHqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 0. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆæœ€æ–°ç‰ˆï¼‰        â˜…åˆå›ã ã‘å®Ÿè¡Œã§ OK\n",
        "# -----------------------------------------------------------\n",
        "!pip install -q --upgrade \\\n",
        "  trl accelerate transformers peft bitsandbytes datasets sentencepiece"
      ],
      "metadata": {
        "id": "oNQhyACScLLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 1. Drive ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç½®ãå ´ã‚’æ±ºå®š\n",
        "# -----------------------------------------------------------\n",
        "from google.colab import drive, runtime, output\n",
        "drive.mount(\"/content/drive\")\n",
        "CKPT_DIR = \"/content/drive/MyDrive/hf_ckpt/hameln_dpo_lora\""
      ],
      "metadata": {
        "id": "h_pYhduBnxLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 2. Hugging Face èªè¨¼   â˜…Hameln åˆ©ç”¨è¦ç´„ã«åŒæ„æ¸ˆã¿ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "# -----------------------------------------------------------\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "sjmFco8NcjII",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 3. ãƒ¢ãƒ‡ãƒ« & ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ 4-bit ã§ãƒ­ãƒ¼ãƒ‰\n",
        "# -----------------------------------------------------------\n",
        "import torch, os, glob\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "BASE_ID = \"Elizezen/Hameln-japanese-mistral-7B\"\n",
        "\n",
        "bnb_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "tok = AutoTokenizer.from_pretrained(BASE_ID, use_fast=False)\n",
        "tok.pad_token = tok.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_ID,\n",
        "    quantization_config=bnb_cfg,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "-O86CCjcc4li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 4. LoRA è¨­å®š\n",
        "# -----------------------------------------------------------\n",
        "from peft import LoraConfig\n",
        "lora_cfg = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "                    \"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "zQQZBoHAeJYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆHF Hub ã‹ã‚‰ç›´ DLï¼‰\n",
        "# -----------------------------------------------------------\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import os, glob\n",
        "\n",
        "# â¶ Drive ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½œæˆã—ã¦å†åˆ©ç”¨\n",
        "DS_CACHE = \"/content/drive/MyDrive/hf_cache/anthropic_jp\"\n",
        "\n",
        "if os.path.exists(DS_CACHE):\n",
        "    print(\"â–¶ Drive ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å³æ™‚ãƒ­ãƒ¼ãƒ‰ â€¦\")\n",
        "    train_ds = load_from_disk(DS_CACHE)\n",
        "else:\n",
        "    print(\"â–¶ Hugging Face Hub ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ â€¦\")\n",
        "    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ split ã¯ trainï¼ˆ161k è¡Œï¼‰\n",
        "    train_ds = load_dataset(\"shi3z/anthropic_hh_rlhf_japanese\", split=\"train\")\n",
        "    # é¸å¥½åˆ—ã¯ã™ã§ã« chosen / rejected ã§æƒã£ã¦ã„ã‚‹ã®ã§ãƒªãƒãƒ¼ãƒ ä¸è¦ :contentReference[oaicite:0]{index=0}\n",
        "    train_ds.save_to_disk(DS_CACHE)\n",
        "    print(\"âœ… Drive ã«ä¿å­˜ã—ã¾ã—ãŸ â†’\", DS_CACHE)\n",
        "\n",
        "print(\"ãƒ‡ãƒ¼ã‚¿è¡Œæ•°:\", len(train_ds), \"/ åˆ—:\", train_ds.column_names)\n"
      ],
      "metadata": {
        "id": "_zKugKlqeyNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 6. DPOConfig â”€ ã“ã¾ã‚ä¿å­˜ + ãƒ¡ãƒ¢ãƒªå‰Šæ¸›\n",
        "# -----------------------------------------------------------\n",
        "from trl import DPOConfig\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # æ–­ç‰‡åŒ–å›é¿\n",
        "\n",
        "dpo_cfg = DPOConfig(\n",
        "    output_dir              = CKPT_DIR,\n",
        "    per_device_train_batch_size = 1,      # ãƒ¡ãƒ¢ãƒªç¯€ç´„\n",
        "    gradient_accumulation_steps = 8,      # å®Ÿãƒãƒƒãƒ 8\n",
        "    gradient_checkpointing      = True,   # å‹¾é… CP ã§ 30% ç¯€ç´„\n",
        "    num_train_epochs            = 1,\n",
        "    learning_rate               = 2e-4,\n",
        "    beta                        = 0.1,\n",
        "    logging_steps               = 50,\n",
        "    save_steps                  = 200,    # 200 ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã« Drive ã¸ä¿å­˜\n",
        "    eval_steps                  = 200,\n",
        "    bf16                        = True,   # A100 ç”¨\n",
        ")"
      ],
      "metadata": {
        "id": "2Q5LOjrqe6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 7. æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•æ¤œå‡º\n",
        "# -----------------------------------------------------------\n",
        "ckpts = sorted(glob.glob(f\"{CKPT_DIR}/checkpoint-*\"), key=os.path.getmtime)\n",
        "resume_ckpt = ckpts[-1] if ckpts else None\n",
        "print(\"å†é–‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:\", resume_ckpt)\n"
      ],
      "metadata": {
        "id": "R72uyEpPoR5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 8. DPOTrainer ç”Ÿæˆ & å­¦ç¿’é–‹å§‹ï¼ˆå‚ç…§ãƒ¢ãƒ‡ãƒ«ã¯ CPU ã¸é€€é¿ï¼‰\n",
        "# -----------------------------------------------------------\n",
        "from trl import DPOTrainer\n",
        "trainer = DPOTrainer(\n",
        "    model                 = base_model,\n",
        "    ref_model             = BASE_ID,               # æ–‡å­—åˆ—æŒ‡å®šã§è‡ªå‹•ãƒ­ãƒ¼ãƒ‰\n",
        "    ref_model_init_kwargs = {\"device_map\":\"cpu\",\n",
        "                             \"load_in_4bit\":True,\n",
        "                             \"low_cpu_mem_usage\":True},\n",
        "    args                  = dpo_cfg,\n",
        "    processing_class      = tok,\n",
        "    train_dataset         = train_ds,\n",
        "    peft_config           = lora_cfg,              # ãã®ã¾ã¾æ¸¡ã™\n",
        "    resume_from_checkpoint= resume_ckpt,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "uteeM1H3e-1i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# 9. å­¦ç¿’å®Œäº†å¾Œã® LoRA ã‚¢ãƒ€ãƒ—ã‚¿ä¿å­˜\n",
        "# -----------------------------------------------------------\n",
        "trainer.model.save_pretrained(CKPT_DIR + \"/final-lora\")\n",
        "tok.save_pretrained(CKPT_DIR + \"/final-lora\")\n",
        "print(\"âœ… ã™ã¹ã¦å®Œäº†ï¼ï¼ˆLoRA ã¯ Drive ã«ä¿å­˜æ¸ˆã¿ï¼‰\")"
      ],
      "metadata": {
        "id": "n094d8FRoX40"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1jjC9CRpQ51dPcBHFha3fNbVbR3vAQsHD",
      "authorship_tag": "ABX9TyO3F3QBQhEu+x4y5vDxxDHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}