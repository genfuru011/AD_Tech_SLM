{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD_Tech_SLM - DPO Training Notebook\n",
    "\n",
    "このノートブックは、広告特化型SLMのDPOトレーニングを実行するためのインタラクティブな環境です。\n",
    "\n",
    "## 環境\n",
    "- MacBook Air M2 8GB\n",
    "- Metal Performance Shaders (MPS) GPU\n",
    "- DPO (Direct Preference Optimization) 手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# プロジェクトルートを追加\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイス確認\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"🚀 Metal Performance Shaders (MPS) is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, using CPU\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットを読み込み\n",
    "dataset_path = project_root / \"data\" / \"sample_dpo_dataset.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"データセットのサンプル数: {len(df)}\")\n",
    "print(f\"カラム: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの統計情報\n",
    "print(\"=== データ統計 ===\")\n",
    "print(f\"プロンプトの平均文字数: {df['prompt'].str.len().mean():.1f}\")\n",
    "print(f\"chosenの平均文字数: {df['chosen'].str.len().mean():.1f}\")\n",
    "print(f\"rejectedの平均文字数: {df['rejected'].str.len().mean():.1f}\")\n",
    "\n",
    "print(\"\\n=== サンプル例 ===\")\n",
    "sample = df.iloc[0]\n",
    "print(f\"プロンプト: {sample['prompt']}\")\n",
    "print(f\"Chosen: {sample['chosen']}\")\n",
    "print(f\"Rejected: {sample['rejected']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルとトークナイザーの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# モデル名（M2 8GBに適したサイズ）\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "\n",
    "print(f\"モデルを読み込み中: {model_name}\")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"✅ トークナイザー読み込み完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" if torch.backends.mps.is_available() else None,\n",
    ")\n",
    "\n",
    "print(\"✅ ベースモデル読み込み完了\")\n",
    "print(f\"モデルパラメータ数: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LoRA設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA設定\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "# LoRAモデルの作成\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"✅ LoRA設定完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# HuggingFace Datasetに変換\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 訓練・検証分割\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "eval_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "\n",
    "print(f\"訓練データ: {len(train_dataset)} サンプル\")\n",
    "print(f\"検証データ: {len(eval_dataset)} サンプル\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 簡単な推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ad_copy(prompt, max_length=150):\n",
    "    \"\"\"広告コピーを生成する関数\"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    if torch.backends.mps.is_available():\n",
    "        inputs = inputs.to(\"mps\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # プロンプト部分を除去\n",
    "    if generated_text.startswith(prompt):\n",
    "        generated_text = generated_text[len(prompt):].strip()\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# テスト実行\n",
    "test_prompt = \"【テーマ】雨の日でもワクワクするニュースアプリを紹介してください\"\n",
    "result = generate_ad_copy(test_prompt)\n",
    "\n",
    "print(f\"プロンプト: {test_prompt}\")\n",
    "print(f\"生成結果: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DPO トレーニングの準備\n",
    "\n",
    "実際のDPOトレーニングは `scripts/train_dpo.py` を使用して実行します。\n",
    "\n",
    "ターミナルで以下のコマンドを実行してください：\n",
    "\n",
    "```bash\n",
    "cd /path/to/AD_Tech_SLM\n",
    "python scripts/train_dpo.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. モデル評価\n",
    "\n",
    "トレーニング後のモデルを評価するセクション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング済みモデルを読み込んで評価する場合\n",
    "# このセクションはトレーニング完了後に実行\n",
    "\n",
    "test_prompts = [\n",
    "    \"【テーマ】健康管理をサポートするフィットネスアプリを紹介してください\",\n",
    "    \"【テーマ】料理初心者向けのレシピアプリを紹介してください\",\n",
    "    \"【テーマ】読書好きのための電子書籍アプリを紹介してください\",\n",
    "]\n",
    "\n",
    "print(\"=== 生成テスト ===\")\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    result = generate_ad_copy(prompt)\n",
    "    print(f\"\\nテスト {i}:\")\n",
    "    print(f\"プロンプト: {prompt}\")\n",
    "    print(f\"生成結果: {result}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}