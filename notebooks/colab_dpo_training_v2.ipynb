{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876fdb64",
   "metadata": {},
   "source": [
    "# 🦆 TinySwallow-1.5B DPO Training on Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/AD_Tech_SLM/blob/main/notebooks/colab_dpo_training_v2.ipynb)\n",
    "\n",
    "**Direct Preference Optimization (DPO) Training for Japanese Language Model**\n",
    "\n",
    "- **Model**: SakanaAI/TinySwallow-1.5B-Instruct\n",
    "- **Target**: 広告技術分野の専門知識向上\n",
    "- **Framework**: TRL 0.18.1 + Transformers\n",
    "- **Hardware**: Google Colab GPU (T4/V100/A100)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8cd66",
   "metadata": {},
   "source": [
    "## 🛠️ 1. 環境セットアップ\n",
    "\n",
    "### GPU確認と必要ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a539f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU確認\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"🔧 PyTorch Version: {torch.__version__}\")\n",
    "print(f\"🚀 CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"📱 GPU Device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df32ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最新の依存関係をインストール\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers==4.52.4\n",
    "!pip install -q trl==0.18.1\n",
    "!pip install -q datasets==3.1.0\n",
    "!pip install -q peft==0.15.0\n",
    "!pip install -q bitsandbytes==0.44.1\n",
    "!pip install -q accelerate==1.2.1\n",
    "!pip install -q wandb\n",
    "!pip install -q tensorboard\n",
    "\n",
    "# Colab特有の問題解決\n",
    "!pip install -q tf-keras\n",
    "\n",
    "print(\"✅ 依存関係のインストール完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791b200",
   "metadata": {},
   "source": [
    "### 必要ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1de4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Transformers & TRL\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# Colab用設定\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"📦 ライブラリインポート完了\")\n",
    "print(f\"🔧 TRL Version: {trl.__version__ if 'trl' in globals() else 'Not found'}\")\n",
    "print(f\"🤖 Transformers Version: {transformers.__version__ if 'transformers' in globals() else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4ad81",
   "metadata": {},
   "source": [
    "## ⚙️ 2. 設定とデータセット準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング設定\n",
    "CONFIG = {\n",
    "    # モデル設定\n",
    "    \"model_name\": \"SakanaAI/TinySwallow-1.5B-Instruct\",\n",
    "    \"backup_models\": [\n",
    "        \"tokyotech-llm/Swallow-1.5b-instruct-hf\",\n",
    "        \"rinna/japanese-gpt-neox-3.6b-instruction-sft\"\n",
    "    ],\n",
    "    \n",
    "    # トレーニング設定（Colab GPU最適化）\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"max_steps\": 500,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 1e-6,\n",
    "    \"warmup_steps\": 50,\n",
    "    \"eval_steps\": 50,\n",
    "    \"save_steps\": 100,\n",
    "    \"logging_steps\": 10,\n",
    "    \n",
    "    # DPO設定\n",
    "    \"beta\": 0.1,\n",
    "    \"max_length\": 1024,\n",
    "    \"max_prompt_length\": 512,\n",
    "    \n",
    "    # LoRA設定\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    \n",
    "    # データセット設定\n",
    "    \"test_size\": 0.1,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # 出力設定\n",
    "    \"output_dir\": \"./outputs/colab_dpo_training\",\n",
    "}\n",
    "\n",
    "print(\"✅ 設定完了\")\n",
    "print(f\"📋 使用モデル: {CONFIG['model_name']}\")\n",
    "print(f\"🎯 最大ステップ数: {CONFIG['max_steps']}\")\n",
    "print(f\"📊 バッチサイズ: {CONFIG['per_device_train_batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19aed4",
   "metadata": {},
   "source": [
    "### サンプルデータセットの作成\n",
    "\n",
    "広告技術分野に特化したDPOデータセットを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 広告技術分野のサンプルDPOデータセット\n",
    "sample_dpo_data = [\n",
    "    {\n",
    "        \"prompt\": \"プログラマティック広告のRTBについて説明してください。\",\n",
    "        \"chosen\": \"RTB（Real-Time Bidding）は、広告枠の売買をリアルタイムのオークション形式で行う仕組みです。ユーザーがWebページにアクセスした瞬間に、そのユーザーの属性や閲覧履歴に基づいて、広告主が自動的に入札を行います。最も高い金額を提示した広告主の広告が表示される仕組みで、効率的なターゲティングと費用対効果の向上を実現します。\",\n",
    "        \"rejected\": \"RTBは広告を表示するシステムです。\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"DSPとSSPの違いを教えてください。\",\n",
    "        \"chosen\": \"DSP（Demand-Side Platform）は広告主側のプラットフォームで、広告枠の購入を自動化し、ターゲティングや入札戦略の最適化を行います。一方、SSP（Supply-Side Platform）はメディア側のプラットフォームで、広告枠の販売を自動化し、収益の最大化を図ります。DSPは買い手、SSPは売り手の立場でプログラマティック広告の取引を支援します。\",\n",
    "        \"rejected\": \"DSPとSSPは両方とも広告関連のシステムです。\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"クッキーレス時代の広告ターゲティング手法について説明してください。\",\n",
    "        \"chosen\": \"クッキーレス時代では、以下の手法が重要となります：1) ファーストパーティデータの活用（自社の顧客データベース）、2) コンテキスト広告（Webページの内容に基づいたターゲティング）、3) コホート分析（類似ユーザーグループでの分析）、4) プライバシーサンドボックス技術（Googleが提案する新技術群）、5) IDソリューション（メールアドレスベースの識別子）などがあります。\",\n",
    "        \"rejected\": \"クッキーが使えなくなるので、新しい方法を考える必要があります。\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"アトリビューション分析の重要性について教えてください。\",\n",
    "        \"chosen\": \"アトリビューション分析は、コンバージョンに至るまでの各タッチポイントの貢献度を測定する分析手法です。ユーザーの購買行動は複雑で、複数の広告接触を経てコンバージョンに至るため、ラストクリック以外の接触点の価値も適切に評価する必要があります。これにより、マーケティング予算の最適配分、チャネル間の相互作用の理解、ROIの正確な測定が可能になります。\",\n",
    "        \"rejected\": \"アトリビューション分析は広告の効果を測定する方法です。\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"ヘッダービディングとは何ですか？\",\n",
    "        \"chosen\": \"ヘッダービディング（Header Bidding）は、複数のSSPやアドエクスチェンジが同時に広告枠に入札できる仕組みです。従来のウォーターフォール方式とは異なり、すべての需要源が同じタイミングで競合できるため、より公平で透明性の高いオークションが実現されます。結果として、パブリッシャーの収益向上と広告主の効率的な配信が可能になります。\",\n",
    "        \"rejected\": \"ヘッダービディングは広告枠を売る方法の一つです。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# より多くのサンプルデータを生成（実際のプロジェクトでは実データを使用）\n",
    "extended_data = []\n",
    "for i in range(50):  # 50回繰り返してデータを拡張\n",
    "    for base_data in sample_dpo_data:\n",
    "        extended_data.append({\n",
    "            \"prompt\": base_data[\"prompt\"],\n",
    "            \"chosen\": base_data[\"chosen\"],\n",
    "            \"rejected\": base_data[\"rejected\"]\n",
    "        })\n",
    "\n",
    "print(f\"📊 サンプルデータセット作成完了: {len(extended_data)} サンプル\")\n",
    "print(f\"📝 サンプル例:\")\n",
    "print(f\"  Prompt: {sample_dpo_data[0]['prompt'][:50]}...\")\n",
    "print(f\"  Chosen: {sample_dpo_data[0]['chosen'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833f0ef",
   "metadata": {},
   "source": [
    "## 🤖 3. モデルとトークナイザーの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーの読み込み\n",
    "def load_tokenizer(model_name):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        # パディングトークンの設定\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            logger.info(\"🔧 パディングトークンを設定\")\n",
    "        \n",
    "        return tokenizer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ トークナイザー読み込みエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# メインモデルを試行\n",
    "tokenizer = load_tokenizer(CONFIG[\"model_name\"])\n",
    "\n",
    "# 失敗した場合はバックアップモデルを試行\n",
    "if tokenizer is None:\n",
    "    for backup_model in CONFIG[\"backup_models\"]:\n",
    "        logger.info(f\"🔄 バックアップモデルを試行: {backup_model}\")\n",
    "        tokenizer = load_tokenizer(backup_model)\n",
    "        if tokenizer is not None:\n",
    "            CONFIG[\"model_name\"] = backup_model\n",
    "            break\n",
    "\n",
    "if tokenizer is None:\n",
    "    raise ValueError(\"❌ すべてのモデルの読み込みに失敗しました\")\n",
    "\n",
    "print(f\"✅ トークナイザー読み込み完了: {CONFIG['model_name']}\")\n",
    "print(f\"📏 語彙サイズ: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量子化設定（GPU メモリ節約）\n",
    "def create_bnb_config():\n",
    "    return BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "# モデルの読み込み\n",
    "def load_model(model_name, use_quantization=True):\n",
    "    try:\n",
    "        model_kwargs = {\n",
    "            \"trust_remote_code\": True,\n",
    "            \"torch_dtype\": torch.bfloat16,\n",
    "            \"device_map\": \"auto\",\n",
    "        }\n",
    "        \n",
    "        if use_quantization:\n",
    "            model_kwargs[\"quantization_config\"] = create_bnb_config()\n",
    "            logger.info(\"🔧 4bit量子化を使用\")\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            **model_kwargs\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ モデル読み込みエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# モデル読み込み実行\n",
    "model = load_model(CONFIG[\"model_name\"])\n",
    "\n",
    "if model is None:\n",
    "    raise ValueError(\"❌ モデルの読み込みに失敗しました\")\n",
    "\n",
    "print(f\"✅ モデル読み込み完了: {CONFIG['model_name']}\")\n",
    "print(f\"📊 パラメータ数: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"💾 モデルサイズ: {sum(p.numel() * p.element_size() for p in model.parameters()) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda99653",
   "metadata": {},
   "source": [
    "### LoRA設定の適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f266c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    target_modules=CONFIG[\"target_modules\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 量子化されたモデルの準備\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 訓練可能パラメータの確認\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_percentage = 100 * trainable_params / total_params\n",
    "\n",
    "print(f\"🔧 LoRA設定適用完了\")\n",
    "print(f\"📈 訓練可能パラメータ: {trainable_params:,} ({trainable_percentage:.2f}%)\")\n",
    "print(f\"📊 総パラメータ数: {total_params:,}\")\n",
    "\n",
    "# メモリ使用量確認\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"💾 GPU メモリ使用量: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bee95",
   "metadata": {},
   "source": [
    "## 📊 4. データセット準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f281cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成と分割\n",
    "dataset = Dataset.from_list(extended_data)\n",
    "\n",
    "# 訓練・検証データの分割\n",
    "split_dataset = dataset.train_test_split(\n",
    "    test_size=CONFIG[\"test_size\"],\n",
    "    seed=CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"✅ データセット準備完了\")\n",
    "print(f\"📊 訓練データ: {len(train_dataset)} サンプル\")\n",
    "print(f\"📊 検証データ: {len(eval_dataset)} サンプル\")\n",
    "\n",
    "# サンプルデータの確認\n",
    "print(f\"\\n📝 訓練データのサンプル:\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Prompt: {sample['prompt'][:100]}...\")\n",
    "print(f\"  Chosen: {sample['chosen'][:100]}...\")\n",
    "print(f\"  Rejected: {sample['rejected'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1dcf1c",
   "metadata": {},
   "source": [
    "## 🚀 5. DPOトレーニング設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c36860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力ディレクトリの作成\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "# DPOConfig設定（TRL 0.18.1対応）\n",
    "training_args = DPOConfig(\n",
    "    output_dir=CONFIG[\"output_dir\"],\n",
    "    num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
    "    max_steps=CONFIG[\"max_steps\"],\n",
    "    per_device_train_batch_size=CONFIG[\"per_device_train_batch_size\"],\n",
    "    per_device_eval_batch_size=CONFIG[\"per_device_eval_batch_size\"],\n",
    "    gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "    eval_steps=CONFIG[\"eval_steps\"],\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    logging_steps=CONFIG[\"logging_steps\"],\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,  # GPU用\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[\"tensorboard\"],  # Colab用\n",
    "    # DPO固有のパラメータ\n",
    "    beta=CONFIG[\"beta\"],\n",
    "    max_length=CONFIG[\"max_length\"],\n",
    "    max_prompt_length=CONFIG[\"max_prompt_length\"],\n",
    ")\n",
    "\n",
    "print(f\"✅ DPOConfig設定完了\")\n",
    "print(f\"📋 最大ステップ数: {CONFIG['max_steps']}\")\n",
    "print(f\"🎯 学習率: {CONFIG['learning_rate']}\")\n",
    "print(f\"🔥 DPO Beta: {CONFIG['beta']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPOTrainer の初期化（TRL 0.18.1対応）\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,  # 新しいAPI\n",
    ")\n",
    "\n",
    "print(f\"✅ DPOTrainer初期化完了\")\n",
    "print(f\"🔧 使用API: TRL 0.18.1\")\n",
    "\n",
    "# メモリ使用量の最終確認\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "    print(f\"💾 GPU メモリ (割り当て済み): {allocated:.2f} GB\")\n",
    "    print(f\"💾 GPU メモリ (予約済み): {reserved:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2285cb9",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ 6. DPOトレーニング実行\n",
    "\n",
    "**注意**: トレーニングには30分〜1時間程度かかる場合があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング開始時刻の記録\n",
    "start_time = datetime.now()\n",
    "print(f\"🚀 DPOトレーニング開始: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"📊 予想所要時間: 30-60分\")\n",
    "print(f\"📈 進捗は下記で確認できます:\")\n",
    "\n",
    "try:\n",
    "    # トレーニング実行\n",
    "    trainer.train()\n",
    "    \n",
    "    # 完了時刻の計算\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n✅ トレーニング完了!\")\n",
    "    print(f\"⏱️  所要時間: {duration}\")\n",
    "    print(f\"🎯 最終ステップ: {trainer.state.global_step}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ トレーニングエラー: {e}\")\n",
    "    # エラーログの詳細表示\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc649ad",
   "metadata": {},
   "source": [
    "## 💾 7. モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終モデルの保存\n",
    "final_output_dir = os.path.join(CONFIG[\"output_dir\"], \"final_model\")\n",
    "os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "# LoRAアダプターの保存\n",
    "trainer.save_model(final_output_dir)\n",
    "tokenizer.save_pretrained(final_output_dir)\n",
    "\n",
    "print(f\"💾 モデル保存完了: {final_output_dir}\")\n",
    "\n",
    "# 保存されたファイルの確認\n",
    "saved_files = os.listdir(final_output_dir)\n",
    "print(f\"📁 保存されたファイル:\")\n",
    "for file in saved_files:\n",
    "    print(f\"  - {file}\")\n",
    "\n",
    "# Hugging Face Hubへのアップロード（オプション）\n",
    "print(f\"\\n🚀 Hugging Face Hubにアップロードする場合:\")\n",
    "print(f\"  trainer.push_to_hub('your-username/tiny-swallow-dpo-adtech')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7027f1a",
   "metadata": {},
   "source": [
    "## 🧪 8. 学習済みモデルのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad92a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用プロンプト\n",
    "test_prompts = [\n",
    "    \"プログラマティック広告のメリットを教えてください。\",\n",
    "    \"DSPの主要な機能について説明してください。\",\n",
    "    \"クッキーレス時代の対策について教えてください。\",\n",
    "    \"広告のアトリビューション分析とは何ですか？\",\n",
    "    \"ヘッダービディングの仕組みを説明してください。\"\n",
    "]\n",
    "\n",
    "print(\"🧪 学習済みモデルのテスト開始\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# テスト実行\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\n🔍 テスト {i}: {prompt}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # トークン化\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # テキスト生成\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=200,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        \n",
    "        # 生成テキストのデコード\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        print(f\"📝 回答: {response}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ エラー: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 テスト完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67b3df",
   "metadata": {},
   "source": [
    "## 📈 9. トレーニング結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoardの起動\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={CONFIG[\"output_dir\"]}/runs\n",
    "\n",
    "print(\"📈 TensorBoard起動完了\")\n",
    "print(\"📊 トレーニングメトリクスを上記で確認できます\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccf4c4",
   "metadata": {},
   "source": [
    "## 📥 10. モデルのダウンロード（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46269ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルをZIPファイルとしてダウンロード\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# ZIPファイルの作成\n",
    "zip_filename = \"tiny_swallow_dpo_model\"\n",
    "shutil.make_archive(zip_filename, 'zip', final_output_dir)\n",
    "\n",
    "print(f\"📦 ZIPファイル作成完了: {zip_filename}.zip\")\n",
    "print(f\"📁 サイズ: {os.path.getsize(f'{zip_filename}.zip') / 1024**2:.1f} MB\")\n",
    "\n",
    "# ダウンロード\n",
    "# files.download(f\"{zip_filename}.zip\")\n",
    "print(\"💾 上記のコメントアウトを解除してダウンロードできます\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0cfb6",
   "metadata": {},
   "source": [
    "## 🎉 完了！\n",
    "\n",
    "### ✅ 達成項目\n",
    "- ✅ TinySwallow-1.5B モデルの読み込み\n",
    "- ✅ 広告技術分野のDPOデータセット作成\n",
    "- ✅ LoRA + 4bit量子化による効率的なファインチューニング\n",
    "- ✅ TRL 0.18.1 最新APIを使用したDPOトレーニング\n",
    "- ✅ 学習済みモデルのテスト\n",
    "- ✅ トレーニング結果の可視化\n",
    "\n",
    "### 📚 次のステップ\n",
    "1. **実際のデータでの訓練**: より大規模で多様な広告技術データセットを使用\n",
    "2. **ハイパーパラメータ調整**: 学習率、betaパラメータの最適化\n",
    "3. **評価メトリクス**: より詳細な評価指標の導入\n",
    "4. **プロダクション展開**: API化やWebアプリケーションとしての展開\n",
    "\n",
    "### 🔗 参考リンク\n",
    "- [TRL Documentation](https://huggingface.co/docs/trl/)\n",
    "- [DPO Paper](https://arxiv.org/abs/2305.18290)\n",
    "- [Transformers Documentation](https://huggingface.co/docs/transformers/)\n",
    "\n",
    "---\n",
    "**🦆 TinySwallow DPO Training Completed Successfully! 🎊**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
